{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "widespread-genetics",
   "metadata": {},
   "source": [
    "### Instalação do XGBoost\n",
    "\n",
    "1. Vá em File -> New -> Terminal e digite o seguinte comando:\n",
    "\n",
    "> conda install -c conda-forge xgboost\n",
    "\n",
    "\n",
    "2. Depois, execute o código abaixo para ver se a instalação funcionou corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "respective-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-marshall",
   "metadata": {},
   "source": [
    "### Versões dos pacotes\n",
    "\n",
    "1. Confira também se os pacotes abaixo estão nas seguintes versões:\n",
    "\n",
    "> Python >= 3.7\n",
    "\n",
    "> numpy >= 1.19.1\n",
    "\n",
    "> SciPy >= 1.5.2\n",
    "\n",
    "> Scikit-Learn >= 0.23.2\n",
    "\n",
    "> XGBoost >= 1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rational-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-10.16-x86_64-i386-64bit\n",
      "Python 3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]\n",
      "NumPy 1.23.5\n",
      "SciPy 1.10.0\n",
      "Scikit-Learn 1.2.1\n",
      "XGBoost 1.7.4\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import numpy; print(\"NumPy\", numpy.__version__)\n",
    "import scipy; print(\"SciPy\", scipy.__version__)\n",
    "import sklearn; print(\"Scikit-Learn\", sklearn.__version__)\n",
    "import xgboost; print(\"XGBoost\", xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-peeing",
   "metadata": {},
   "source": [
    "# Criando algoritmos baselines\n",
    "\n",
    "Antes de analisarmos o algoritmo de Árvore de Decisão, vamos criar aqui algoritmos baseline e compara-los minimanente com o XGBoost, tanto para regressão quanto para classificação. Isso será importante para podermos comparar com os resultados de quando fizermos os ajustes nos hiperparâmetros do XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-salon",
   "metadata": {},
   "source": [
    "### Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continuing-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "numeric-bibliography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  season   yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "0        1     1.0  0.0     1      0.0      6.0         0.0           2   \n",
       "1        2     1.0  0.0     1      0.0      0.0         0.0           2   \n",
       "2        3     1.0  0.0     1      0.0      1.0         1.0           1   \n",
       "3        4     1.0  0.0     1      0.0      2.0         1.0           1   \n",
       "4        5     1.0  0.0     1      0.0      3.0         1.0           1   \n",
       "\n",
       "       temp     atemp       hum  windspeed   cnt  \n",
       "0  0.344167  0.363625  0.805833   0.160446   985  \n",
       "1  0.363478  0.353739  0.696087   0.248539   801  \n",
       "2  0.196364  0.189405  0.437273   0.248309  1349  \n",
       "3  0.200000  0.212122  0.590435   0.160296  1562  \n",
       "4  0.226957  0.229270  0.436957   0.186900  1600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bikes = pd.read_csv('bases/bike_rentals_cleaned.csv', sep=',')\n",
    "df_bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "automotive-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando os dados em features e labels\n",
    "X = df_bikes.iloc[:,:-1]\n",
    "y = df_bikes.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "grateful-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vamos treinar uma regressão linear e comparar com o XGBoost depois\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "binding-forest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 898.21\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"RMSE: %0.2f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "neural-allocation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     731.000000\n",
       "mean     4504.348837\n",
       "std      1937.211452\n",
       "min        22.000000\n",
       "25%      3152.000000\n",
       "50%      4548.000000\n",
       "75%      5956.000000\n",
       "max      8714.000000\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#podemos usar o método describe para tentar qualificar o RMSE\n",
    "df_bikes['cnt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "focal-newfoundland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 705.11\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "xg_reg.fit(X_train, y_train)\n",
    "y_pred = xg_reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"RMSE: %0.2f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-obligation",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "Realizar apenas um teste não é confiável, visto que se você fizer uma divisão dos dados diferente, você obterá diferentes resultados. Para tratar isso, usamos cross-validation, cujo processo já foi explicado na aula de SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "subtle-thermal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg rmse: [ 504.01  840.55 1140.88  728.39  640.2   969.95 1133.45 1252.85 1084.64\n",
      " 1425.33]\n",
      "RMSE mean: 972.02\n"
     ]
    }
   ],
   "source": [
    "#para regressão linear\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=10)\n",
    "rmse = np.sqrt(-scores)\n",
    "print('Reg rmse:', np.round(rmse, 2))\n",
    "print('RMSE mean: %0.2f' % (rmse.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "authorized-replacement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg rmse: [ 717.65  692.8   520.7   737.68  835.96 1006.24  991.34  747.61  891.99\n",
      " 1731.13]\n",
      "RMSE mean: 887.31\n"
     ]
    }
   ],
   "source": [
    "# para XGBoost\n",
    "model = XGBRegressor()\n",
    "scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=10)\n",
    "rmse = np.sqrt(-scores)\n",
    "print('Reg rmse:', np.round(rmse, 2))\n",
    "print('RMSE mean: %0.2f' % (rmse.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-insulin",
   "metadata": {},
   "source": [
    "### Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "primary-utility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header=None)\n",
    "df_census.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "                  'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   'income']\n",
    "df_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "general-musical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_census.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-lending",
   "metadata": {},
   "source": [
    "Quando olhamos para o dataset, vemos a coluna 'education' e 'education_num'. A última é a versão numérica da primeira. Assim, podemos dropar 'education'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dental-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census = df_census.drop(['education'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-community",
   "metadata": {},
   "source": [
    "Todas as colunas precisam ser transformadas em colunas numéricas. O método *get_dumies* do pandas pega valores únicos não-numéricos de cada coluna e os converte em colunas, com 1 indicando presença e 0 ausência. Veja o exemplo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efficient-defendant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Divorced</th>\n",
       "      <th>Married-AF-spouse</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Married-spouse-absent</th>\n",
       "      <th>Never-married</th>\n",
       "      <th>Separated</th>\n",
       "      <th>Widowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Divorced   Married-AF-spouse   Married-civ-spouse  \\\n",
       "0              0                   0                    0   \n",
       "1              0                   0                    1   \n",
       "2              1                   0                    0   \n",
       "3              0                   0                    1   \n",
       "4              0                   0                    1   \n",
       "...          ...                 ...                  ...   \n",
       "32556          0                   0                    1   \n",
       "32557          0                   0                    1   \n",
       "32558          0                   0                    0   \n",
       "32559          0                   0                    0   \n",
       "32560          0                   0                    1   \n",
       "\n",
       "        Married-spouse-absent   Never-married   Separated   Widowed  \n",
       "0                           0               1           0         0  \n",
       "1                           0               0           0         0  \n",
       "2                           0               0           0         0  \n",
       "3                           0               0           0         0  \n",
       "4                           0               0           0         0  \n",
       "...                       ...             ...         ...       ...  \n",
       "32556                       0               0           0         0  \n",
       "32557                       0               0           0         0  \n",
       "32558                       0               0           0         1  \n",
       "32559                       0               1           0         0  \n",
       "32560                       0               0           0         0  \n",
       "\n",
       "[32561 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exemplo\n",
    "pd.get_dummies(df_census['marital-status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "respected-parameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "      <th>income_ &lt;=50K</th>\n",
       "      <th>income_ &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0             0                       0                     0   \n",
       "1             0                       0                     0   \n",
       "2             0                       0                     0   \n",
       "3             0                       0                     0   \n",
       "4             0                       0                     0   \n",
       "\n",
       "   workclass_ Never-worked  ...  native-country_ Scotland  \\\n",
       "0                        0  ...                         0   \n",
       "1                        0  ...                         0   \n",
       "2                        0  ...                         0   \n",
       "3                        0  ...                         0   \n",
       "4                        0  ...                         0   \n",
       "\n",
       "   native-country_ South  native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                      0                       0                         0   \n",
       "1                      0                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       0                         0   \n",
       "4                      0                       0                         0   \n",
       "\n",
       "   native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                                0                              1   \n",
       "1                                0                              1   \n",
       "2                                0                              1   \n",
       "3                                0                              1   \n",
       "4                                0                              0   \n",
       "\n",
       "   native-country_ Vietnam  native-country_ Yugoslavia  income_ <=50K  \\\n",
       "0                        0                           0              1   \n",
       "1                        0                           0              1   \n",
       "2                        0                           0              1   \n",
       "3                        0                           0              1   \n",
       "4                        0                           0              1   \n",
       "\n",
       "   income_ >50K  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census = pd.get_dummies(df_census)\n",
    "df_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-appearance",
   "metadata": {},
   "source": [
    "O objetivo (coluna target) é determinar se uma pessoa ganha mais que 50k ou não. Depois do pd.get_dummies, duas colunas, df_census['income_<=50k'] e df_census['income_>50k] são usadas para determinar se uma pessoa ganha 50k. Visto que ambas representam a mesma coisa, vamos deletar a primeira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "elementary-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census = df_census.drop('income_ <=50K', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "coated-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features e labels\n",
    "X = df_census.iloc[:,:-1]\n",
    "y = df_census.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "democratic-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "strategic-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uma função para executar cross-validation\n",
    "def cross_val(classifier, num_splits=10):\n",
    "    model = classifier\n",
    "    scores = cross_val_score(model, X, y, cv=num_splits)\n",
    "    print('Accuracy:', np.round(scores, 2))\n",
    "    print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "operating-webster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.77 0.78 0.78 0.78 0.78 0.78 0.77 0.78 0.77 0.78]\n",
      "Accuracy mean: 0.78\n"
     ]
    }
   ],
   "source": [
    "cross_val(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "binary-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "diverse-tension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.85 0.86 0.87 0.85 0.86 0.86 0.86 0.87 0.86 0.86]\n",
      "Accuracy mean: 0.86\n"
     ]
    }
   ],
   "source": [
    "cross_val(XGBClassifier(n_estimators=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-vermont",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Vamos começar executando decision trees para comparar os resultados com o dataset df_census e depois entender como usar GridSearch para encontrar os melhores parâmetros para nossa árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "digital-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_census.iloc[:,:-1]\n",
    "y = df_census.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "included-bride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131679154894976"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = DecisionTreeClassifier(random_state=2)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-gregory",
   "metadata": {},
   "source": [
    "Agora vamos treinar uma árvore de regressão usando GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "hybrid-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bikes = pd.read_csv('bases/bike_rentals_cleaned.csv')\n",
    "\n",
    "X_bikes = df_bikes.iloc[:,:-1]\n",
    "y_bikes = df_bikes.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bikes, y_bikes, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "headed-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "engaged-retirement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE mean: 1233.36\n"
     ]
    }
   ],
   "source": [
    "reg = DecisionTreeRegressor(random_state=2)\n",
    "scores = cross_val_score(reg, X_bikes, y_bikes, scoring='neg_mean_squared_error', cv=5)\n",
    "rmse = np.sqrt(-scores)\n",
    "print('RMSE mean: %0.2f' % (rmse.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-auction",
   "metadata": {},
   "source": [
    "Podemos checar se o modelo esta overfitando ou não. para isso, podemos predizer o proprio conjunto de treino e verificar o RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "metropolitan-extraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = DecisionTreeRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_train)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "reg_mse = mean_squared_error(y_train, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "reg_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-covering",
   "metadata": {},
   "source": [
    "Como suspeitamos, o modelo está overfitando. Assim, precisamos usar o GridSearchCV para determinar o melhor valor dos hiperparâmetos.\n",
    "\n",
    "Vamos começar por *max_depth*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "surrounded-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'max_depth':[None,2,3,4,6,8,10,20]}\n",
    "reg = DecisionTreeRegressor(random_state=2)\n",
    "grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "\n",
    "\n",
    "grid_reg.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_reg.best_params_\n",
    "print(\"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "applicable-paintball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 864.670\n"
     ]
    }
   ],
   "source": [
    "#e agora verificamos se com esse valor, o RMSE diminui\n",
    "best_model = grid_reg.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse_test = mean_squared_error(y_test, y_pred)**0.5\n",
    "\n",
    "print('Test score: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-residence",
   "metadata": {},
   "source": [
    "Para testar com outras features, vamos criar uma função para facilitar nosso trabalho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "mysterious-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params, reg=DecisionTreeRegressor(random_state=2)):\n",
    "\n",
    "    grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "    \n",
    "    grid_reg.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_reg.best_params_\n",
    "\n",
    "    print(\"Best params:\", best_params)\n",
    "    \n",
    "    best_score = np.sqrt(-grid_reg.best_score_)\n",
    "\n",
    "    print(\"Training score: {:.3f}\".format(best_score))\n",
    "\n",
    "    y_pred = grid_reg.predict(X_test)\n",
    "\n",
    "    rmse_test = mean_squared_error(y_test, y_pred)**0.5\n",
    "\n",
    "    print('Test score: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "convinced-mixer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'min_samples_leaf': 8}\n",
      "Training score: 896.083\n",
      "Test score: 855.620\n"
     ]
    }
   ],
   "source": [
    "#vamos testar para a feature min_samples_leaf\n",
    "grid_search(params={'min_samples_leaf':[1,2,4,6,8,10,20,30]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-ordinance",
   "metadata": {},
   "source": [
    "Vamos ver o que acontece quando usamos as duas features no gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "higher-portfolio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 6, 'min_samples_leaf': 2}\n",
      "Training score: 870.396\n",
      "Test score: 913.000\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[None,2,3,4,6,8,10,20],'min_samples_leaf':[1,2,4,6,8,10,20,30]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-madison",
   "metadata": {},
   "source": [
    "Surpreendentemente, o score aumentou. Precisamos sempre colocar vários parÂmetros juntos para executar o GridSearch.\n",
    "\n",
    "vamos iniciar min_samples_leaf em 3 e max_depth a partir de 6 e ver o que acontece:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "strategic-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 9, 'min_samples_leaf': 7}\n",
      "Training score: 888.905\n",
      "Test score: 878.538\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[5,6,7,8,9],'min_samples_leaf':[3,5,7,9]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-cedar",
   "metadata": {},
   "source": [
    "Vimos que o score melhorou, mas ainda temos um longo caminho pela frente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-anxiety",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-violation",
   "metadata": {},
   "source": [
    "### Random Forest Classifiers\n",
    "\n",
    "Vamos começar usando o dataset df_census e comparar o Random Forest com Árvores de Decisão e XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "verbal-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "demanding-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_census = df_census.iloc[:,:-1]\n",
    "y_census = df_census.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "academic-finish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.851 0.844 0.851 0.852 0.851]\n",
      "Accuracy mean: 0.850\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10, random_state=2, n_jobs=-1)\n",
    "\n",
    "#n_estimators = número de árvores\n",
    "#n_jobs = quando igual a -1, usa todos os processadores para execução em paralelo\n",
    "\n",
    "scores = cross_val_score(rf, X_census, y_census, cv=5)\n",
    "print('Accuracy:', np.round(scores, 3))\n",
    "print('Accuracy mean: %0.3f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-backup",
   "metadata": {},
   "source": [
    "A versão default do Random Forest forneceu um resultado melhor que o das Árvores de Decisão (81%), mas não tão bom quanto o XGBoost (86%). \n",
    "\n",
    "Mas aqui, a grande questão é: porque RF foi melhor que uma árvore de decisão individual?\n",
    "\n",
    "A resposta curta é: **bagging**. Com 10 árvores (n_estimator=10), cada predição é baseada em 10 árvores de decisão ao invés de em apenas uma. O Bootstrap age também, fornecendo diversidade e reduzindo a variância.\n",
    "\n",
    "Por padrão, Random Forest Classifiers selecionam a partir da raiz quadrada do número total de features ao fazer um split. Então, se existem 100 features (Colunas), cada árvore de decisão vai considerar apenas 10 features quando fazer o split. Assim, duas árvores com amostras duplicadas podem fornecer predições muito diferentes devido aos diferentes splits. Essa é outra maneira de reduzir variância.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-judges",
   "metadata": {},
   "source": [
    "### Random Forest Regressor\n",
    "\n",
    "Numa Random Forest Regressor, os exemplos são amostrados com reposição, da mesma maneira que num Random Forest Classifier, mas o número máximo de features é o número total de features ao invés da raiz quadrada. Isto é devido a experimentos. Veja [aqui](https://orbi.uliege.be/bitstream/2268/9357/1/geurts-mlj-advance.pdf)\n",
    "\n",
    "Além disso, a predição final é feita levando em consideração a média das predições de todas as árvores ao invés de regras baseadas em voto majoritário. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "failing-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bikes = df_bikes.iloc[:,:-1]\n",
    "y_bikes = df_bikes.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "formed-mortality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [ 801.486  579.987  551.347  846.698  895.05  1097.522  893.738  809.284\n",
      "  833.488 2145.046]\n",
      "RMSE mean: 945.365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=2, n_jobs=-1)\n",
    "scores = cross_val_score(rf, X_bikes, y_bikes, scoring='neg_mean_squared_error', cv=10)\n",
    "\n",
    "rmse = np.sqrt(-scores)\n",
    "print('RMSE:', np.round(rmse, 3))\n",
    "print('RMSE mean: %0.3f' % (rmse.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-customs",
   "metadata": {},
   "source": [
    "Vamos agora ajustar os hiperparâmetros do Random Forest e aproveitar para introduzir uma nova maneira de fazer GridSearch, chamada de RandomizedSearchCV. A ideia é a mesma por trás do GridSearchCV, porém, como este pode levar muito tempo, RandomizedSearchCV trabalha escolhendo um número aleatório de combinações. Não foi feito para ser exaustivo, mas sim para encontrar a melhor combinação de parâmetros num tempo limitado.\n",
    "\n",
    "\n",
    "Vamos voltar a dataset df_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "blond-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bikes, y_bikes, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "organized-season",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [ 836.482  541.898  533.086  812.782  894.877  881.117  794.103  828.968\n",
      "  772.517 2128.148]\n",
      "RMSE mean: 902.398\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=50, warm_start=True, n_jobs=-1, random_state=2)\n",
    "scores = cross_val_score(rf, X_bikes, y_bikes, scoring='neg_mean_squared_error', cv=10)\n",
    "rmse = np.sqrt(-scores)\n",
    "print('RMSE:', np.round(rmse, 3))\n",
    "print('RMSE mean: %0.3f' % (rmse.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-treasurer",
   "metadata": {},
   "source": [
    "Introduzimos um novo parâmetro aqui: **warm_start**.\n",
    "\n",
    "Quando warm_star=True, adicionar mais árvores não requer começar tudo do zero. Se você mudar n_stimators de 100 para 200, Random Forest vai reusar a solução do fit() anterior, tornando a execução mais rápida. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-thesis",
   "metadata": {},
   "source": [
    "Agora vamos usar o RandomizedSearchCV. Para isso, vamos criar uma função que recebe os parâmetros que eu quero otimizar, a quantidade de vezes que vamos executar o algoritmo e o regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "planned-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "def randomized_search_reg(params, runs=16, reg=RandomForestRegressor(random_state=2, n_jobs=-1)):\n",
    "    rand_reg = RandomizedSearchCV(reg, params, n_iter=runs, scoring='neg_mean_squared_error', \n",
    "                                  cv=10, n_jobs=-1, random_state=2)\n",
    "    \n",
    "    rand_reg.fit(X_train, y_train)\n",
    "\n",
    "    best_model = rand_reg.best_estimator_\n",
    "\n",
    "    best_params = rand_reg.best_params_\n",
    "\n",
    "    print(\"Best params:\", best_params)\n",
    "    \n",
    "    best_score = np.sqrt(-rand_reg.best_score_)\n",
    "\n",
    "    print(\"Training score: {:.3f}\".format(best_score))\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    rmse_test = MSE(y_test, y_pred)**0.5\n",
    "    \n",
    "    print('Test set score: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "graduate-panel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_features': 0.6, 'max_depth': 12}\n",
      "Training score: 675.128\n",
      "Test set score: 619.014\n"
     ]
    }
   ],
   "source": [
    "#agora executamos\n",
    "\n",
    "randomized_search_reg(params={\n",
    "                          'min_samples_leaf':[1,2,4,6,8,10,20,30],\n",
    "                          'min_impurity_decrease':[0.0, 0.01, 0.05, 0.10, 0.15, 0.2],\n",
    "                          'max_features':['auto', 0.8, 0.7, 0.6, 0.5, 0.4],\n",
    "                          'max_depth':[None,4,6,8,10,12,15,20]\n",
    "                         }, runs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-bulgarian",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-steps",
   "metadata": {},
   "source": [
    "Para entendermos a maneira correra que o Gradient Boosting funciona, vamos usar uma Árvore de Regressão. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adolescent-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bikes = df_bikes.iloc[:,:-1]\n",
    "y_bikes = df_bikes.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bikes, y_bikes, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-watson",
   "metadata": {},
   "source": [
    "1. Aqui, vamos usar um base learner, então configuramos max_depth=2, pois queremos aprender a partir dos erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sticky-dimension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos treinar um Decision tree Regressor\n",
    "tree_1 = DecisionTreeRegressor(max_depth=2, random_state=2)\n",
    "tree_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-organization",
   "metadata": {},
   "source": [
    "2. Vamos fazer predição com o conjunto de treino: ao invés de fazer predições com o conjunto de teste, no gradient boosting as predições são feitas inicialmente com o conjunto de treino. Porque? Para comparar os residuals, precisamos comparar as predições enquanto estamos na fase de treino. A fase de teste do modelo acontece no final, quando todas as árvores estiverem construídas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "chicken-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = tree_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-investment",
   "metadata": {},
   "source": [
    "3. Agora, calculamos os residuals: a diferença entre o predito e o observado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "unauthorized-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_train = y_train - y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-southeast",
   "metadata": {},
   "source": [
    "**NOTA**: os residuals são definidos como y2_train por que agora eles são as labels da próxima árvore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-alaska",
   "metadata": {},
   "source": [
    "4. Treine uma nova árvore em cima dos residuals. Isso vai, gradativamente, diminuindo os residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "continental-philippines",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_2 = DecisionTreeRegressor(max_depth=2, random_state=2)\n",
    "tree_2.fit(X_train, y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-dutch",
   "metadata": {},
   "source": [
    "5. Repita os passos 2 a 4. Conforme o processo continua, os residuals gradativamente vão se aproximando de 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "latter-congo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_train_pred = tree_2.predict(X_train)\n",
    "y3_train = y2_train - y2_train_pred\n",
    "\n",
    "\n",
    "tree_3 = DecisionTreeRegressor(max_depth=2, random_state=2)\n",
    "tree_3.fit(X_train, y3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-variable",
   "metadata": {},
   "source": [
    "6. Agora somamos os resultados: somar os resultados requer fazer predições para cada árvore com o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "blank-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred = tree_1.predict(X_test)\n",
    "\n",
    "y2_pred = tree_2.predict(X_test)\n",
    "\n",
    "y3_pred = tree_3.predict(X_test)\n",
    "\n",
    "y_pred = y1_pred + y2_pred + y3_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-south",
   "metadata": {},
   "source": [
    "7. Agora, podemos calcular o MSE para obter os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eastern-finnish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911.0479538776444"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y_test, y_pred)**0.5\n",
    "#um resultado excelente para um weak learner, principalmente quando comparamos com o resultado da \n",
    "#árvore de regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-volunteer",
   "metadata": {},
   "source": [
    "### Gradient Boosting usando sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-modification",
   "metadata": {},
   "source": [
    "Podemos treinar um Gradiet Boosting usando a scikit-learn para ver se chegamos no mesmo resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "annoying-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "indie-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911.0479538776439"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=2, n_estimators=3, random_state=2, learning_rate=1.0)\n",
    "\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "MSE(y_test, y_pred)**0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-seminar",
   "metadata": {},
   "source": [
    "Temos um novo parâmetro: learning_rate. Para entender sua influência (e também no XGBoost), vamos treinar dois GBs mudando somente *n_estimators*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adjusted-public",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857.1072323426944"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=2, n_estimators=30, random_state=2, learning_rate=1.0)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "MSE(y_test, y_pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-optimization",
   "metadata": {},
   "source": [
    "Uma melhora significativa. Vamos testar com 300, então."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "optical-decision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936.3617413678853"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=2, n_estimators=300, random_state=2, learning_rate=1.0)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "MSE(y_test, y_pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-sleeping",
   "metadata": {},
   "source": [
    "Opa! Algo de errado não está certo. Aqui vemos a importância do learning_rate. \n",
    "\n",
    "Basicamente, a ideia consiste em reduzir a contribuição de árvores individuais de modo que nenhuma árvore tenha muita influência ao construir o modelo, ou seja, o learning rate limita a influência de árvores individuais. Assim, se diminuirmos seu valor, veremos uma grande diferença:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "focused-isaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653.7456840231495"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=2, n_estimators=300, random_state=2, learning_rate=0.1) #default sklearn\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "MSE(y_test, y_pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-mistress",
   "metadata": {},
   "source": [
    "Agora, podemos executar um RandomizedSearchCV e encontrar os melhores parâmetros (Dentro de um range específico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dried-prime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'subsample': 0.65, 'n_estimators': 300, 'learning_rate': 0.05}\n",
      "Training score: 636.200\n",
      "Test set score: 625.985\n"
     ]
    }
   ],
   "source": [
    "params={'subsample':[0.65, 0.7, 0.75],\n",
    "                          'n_estimators':[300, 500, 1000],\n",
    "                          'learning_rate':[0.05, 0.075, 0.1]\n",
    "       }\n",
    "gbr = GradientBoostingRegressor(max_depth=3, random_state=2)\n",
    "\n",
    "rand_reg = RandomizedSearchCV(gbr, params, n_iter=10, scoring='neg_mean_squared_error', \n",
    "                              cv=5, n_jobs=-1, random_state=2)\n",
    "\n",
    "rand_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_model = rand_reg.best_estimator_\n",
    "best_params = rand_reg.best_params_\n",
    "print(\"Best params:\", best_params)\n",
    "best_score = np.sqrt(-rand_reg.best_score_)\n",
    "print(\"Training score: {:.3f}\".format(best_score))\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse_test = MSE(y_test, y_pred)**0.5\n",
    "print('Test set score: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-trigger",
   "metadata": {},
   "source": [
    "**NOTA**: usamos um parâmetro a mais: subsample. Como o nome sugere, é um subconjunto de amostras. Isso signifca que nem todas as linhas serão incluídas ao construir uma árvore. Quando seu valor é diferente de 1.0, o modelo é classificado como **Stochastic Gradient Descent**, em que *stochastic* significa alguma aleatoriedade é inerente ao modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-flavor",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-tamil",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "hollywood-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "concerned-mechanism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],columns= iris['feature_names'] + ['target'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "alien-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fallen-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'], iris['target'], random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "elegant-prince",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(booster='gbtree', objective='multi:softprob', \n",
    "                    learning_rate=0.1, n_estimators=100, random_state=2, n_jobs=-1)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Score: ' + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-intranet",
   "metadata": {},
   "source": [
    "Algumas considerações sobre os parâmetros:\n",
    "\n",
    "1. **booster='gbtree'**: booster é o *base learner*. 'gbtree' é o gradient boosted tree\n",
    "\n",
    "2. **objective='multi:softprob'**: função objetivo. No caso da classificação, calcula a probabilidade de cada classe e escolhe aquela com maior valor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-malaysia",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "divided-stretch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [63.011 59.705 64.538 63.706 64.588]\n",
      "RMSE mean: 63.109\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "X,y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror', \n",
    "                    learning_rate=0.1, n_estimators=100, random_state=2, n_jobs=-1)\n",
    "\n",
    "scores = cross_val_score(xgb, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "rmse = np.sqrt(-scores)\n",
    "print('RMSE:', np.round(rmse, 3))\n",
    "print('RMSE mean: %0.3f' % (rmse.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-gibraltar",
   "metadata": {},
   "source": [
    "1. **objective='reg:squarederror'**: é o MSE a partir do qual derivamos a função objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "selective-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para poder comparar o resultado, podemos verificar usar o método describe na variável y (label) e obter \n",
    "#suas principais estatísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "sixth-proportion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>152.133484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.093005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>140.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>211.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>346.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  442.000000\n",
       "mean   152.133484\n",
       "std     77.093005\n",
       "min     25.000000\n",
       "25%     87.000000\n",
       "50%    140.500000\n",
       "75%    211.500000\n",
       "max    346.000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-transaction",
   "metadata": {},
   "source": [
    "O resultado de 63.124 é menor que 1 desvio padrão, o que é um resultado respeitável. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-castle",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "\n",
    "Agora, temos um template tanto para classificação quanto para regressão que podemos usar como ponto de partida para resolver problemas usando XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-hammer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
